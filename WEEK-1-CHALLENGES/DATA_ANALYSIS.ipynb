{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping ta-lib as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setting up your environment (pip installs)\n",
    "!pip install pandas matplotlib seaborn textblob nltk scikit-learn plotly\n",
    "!pip install talib\n",
    "# Step 2: Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import talib as ta\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "# Step 3: Load the seven CSV files into pandas DataFrames\n",
    "data_path = \"path_to_your_csv_files_directory\"\n",
    "file_names = [\"AAPL_historical_data.csv\", \"AMZN_historical_data.csv\", \"GOOG_historical_data.csv\", \"META_historical_data.csv\", \"MSFT_historical_data.csv\", \"NVDA_historical_data.csv\", \"TSLA_historical_data.csv\"]\n",
    "\n",
    "# Load all CSVs into a dictionary of DataFrames\n",
    "dfs = {file_name: pd.read_csv(os.path.join(data_path, file_name)) for file_name in file_names}\n",
    "\n",
    "# Step 4: Exploratory Data Analysis (EDA)\n",
    "for name, df in dfs.items():\n",
    "    print(f\"Exploring {name}...\")\n",
    "    \n",
    "    # Headline length statistics\n",
    "    df['headline_length'] = df['headline'].apply(len)\n",
    "    print(f\"{name} - Headline Length Stats:\\n\", df['headline_length'].describe(), \"\\n\")\n",
    "    \n",
    "    # Count articles per publisher\n",
    "    print(f\"{name} - Articles per Publisher:\\n\", df['publisher'].value_counts(), \"\\n\")\n",
    "    \n",
    "    # Analyze publication trends over time\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['day_of_week'] = df['date'].dt.day_name()\n",
    "    print(f\"{name} - Articles per Day of Week:\\n\", df['day_of_week'].value_counts(), \"\\n\")\n",
    "    \n",
    "    # Sentiment Analysis\n",
    "    df['sentiment'] = df['headline'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    print(f\"{name} - Sentiment Stats:\\n\", df['sentiment'].describe(), \"\\n\")\n",
    "    \n",
    "    # Keyword & Topic Extraction\n",
    "    vectorizer = CountVectorizer(max_features=10, stop_words='english')\n",
    "    X = vectorizer.fit_transform(df['headline'])\n",
    "    print(f\"{name} - Common Keywords:\\n\", vectorizer.get_feature_names_out(), \"\\n\")\n",
    "    \n",
    "    # Time Series Analysis: Publication frequency\n",
    "    df['publication_day'] = df['date'].dt.date\n",
    "    publication_freq = df['publication_day'].value_counts().sort_index()\n",
    "    print(f\"{name} - Publication Frequency Over Time:\\n\", publication_freq, \"\\n\")\n",
    "    \n",
    "    # Publisher Analysis\n",
    "    unique_publishers = df['publisher'].nunique()\n",
    "    print(f\"{name} - Number of Unique Publishers: {unique_publishers}\\n\")\n",
    "    \n",
    "    # Plotting some trends\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x=publication_freq.index, y=publication_freq.values)\n",
    "    plt.title(f'{name} - Publication Frequency Over Time')\n",
    "    plt.show()\n",
    "\n",
    "# Step 5: Load Stock Price Data (replace with actual stock data file)\n",
    "stock_df = pd.read_csv('path_to_stock_data.csv')\n",
    "\n",
    "# Step 6: Calculate Technical Indicators with TA-Lib\n",
    "stock_df['SMA'] = ta.SMA(stock_df['Close'], timeperiod=20)\n",
    "stock_df['RSI'] = ta.RSI(stock_df['Close'], timeperiod=14)\n",
    "stock_df['MACD'], stock_df['MACD_signal'], stock_df['MACD_hist'] = ta.MACD(stock_df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "# Step 7: Visualize Stock Data with Indicators\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(stock_df['date'], stock_df['Close'], label='Close Price')\n",
    "plt.plot(stock_df['date'], stock_df['SMA'], label='20-Day SMA')\n",
    "plt.title('Stock Price and SMA')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(stock_df['date'], stock_df['RSI'], label='RSI')\n",
    "plt.title('RSI over time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 8: Correlation Analysis between News Sentiment and Stock Movements\n",
    "df = dfs[\"file1.csv\"]  # Example with first file, you can merge or process all as needed\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "stock_df['date'] = pd.to_datetime(stock_df['date']).dt.date\n",
    "\n",
    "# Merge news sentiment with stock data\n",
    "merged_df = pd.merge(df[['date', 'sentiment']], stock_df[['date', 'daily_return']], on='date', how='inner')\n",
    "\n",
    "# Calculate Pearson Correlation\n",
    "correlation = merged_df['sentiment'].corr(merged_df['daily_return'])\n",
    "print(f\"Pearson correlation between Sentiment and Stock Returns: {correlation}\")\n",
    "\n",
    "# Plot the correlation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=merged_df['sentiment'], y=merged_df['daily_return'])\n",
    "plt.title('Correlation between Sentiment and Stock Returns')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Daily Return')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx in /workspace/abrahamnigatu-kifiya-aim2-projects/.venv/lib/python3.12/site-packages (0.2.4)\n",
      "Requirement already satisfied: lxml in /workspace/abrahamnigatu-kifiya-aim2-projects/.venv/lib/python3.12/site-packages (from docx) (5.3.0)\n",
      "Requirement already satisfied: Pillow>=2.0 in /workspace/abrahamnigatu-kifiya-aim2-projects/.venv/lib/python3.12/site-packages (from docx) (10.4.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement exceptions (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for exceptions\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'exceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install docx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install exceptions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshared\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pt\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WD_PARAGRAPH_ALIGNMENT\n",
      "File \u001b[0;32m/workspace/abrahamnigatu-kifiya-aim2-projects/.venv/lib/python3.12/site-packages/docx.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     TAGS \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;167;01mPendingDeprecationWarning\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'exceptions'"
     ]
    }
   ],
   "source": [
    "!pip install python-docx \n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from docx.shared import RGBColor\n",
    "\n",
    "# Create a new Document\n",
    "doc = Document()\n",
    "\n",
    "# Title\n",
    "title = doc.add_heading('Financial News Sentiment Analysis and Stock Movement Correlation', level=1)\n",
    "title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "# Add a section heading and paragraph\n",
    "doc.add_heading('Introduction', level=2)\n",
    "doc.add_paragraph(\n",
    "    \"The goal of this project is to analyze a large corpus of financial news data to uncover correlations \"\n",
    "    \"between news sentiment and stock market movements. This project was designed to refine skills in Data Engineering (DE), \"\n",
    "    \"Financial Analytics (FA), and Machine Learning Engineering (MLE), which are crucial for the demanding environment at Nova Financial Solutions. \"\n",
    "    \"By leveraging advanced data analysis techniques, the project aims to enhance predictive analytics capabilities, significantly boosting \"\n",
    "    \"financial forecasting accuracy and operational efficiency.\"\n",
    ")\n",
    "\n",
    "# Add a section heading and paragraph\n",
    "doc.add_heading('Project Planning and Task Breakdown', level=2)\n",
    "\n",
    "# Task 1\n",
    "doc.add_heading('Task 1: Git and GitHub Setup', level=3)\n",
    "doc.add_paragraph(\n",
    "    \"Objective: Establish a structured and organized project environment.\\n\\n\"\n",
    "    \"Steps:\\n\"\n",
    "    \"1. Repository Setup: A GitHub repository was created with the recommended folder structure, which includes directories for scripts, notebooks, tests, and source code.\\n\"\n",
    "    \"2. Branching: A branch named 'task-1' was created for all developments related to the initial task. Work was committed regularly with descriptive messages to maintain a clear version history.\\n\"\n",
    "    \"3. CI/CD Integration: A simple CI/CD pipeline was set up using GitHub Actions to automate testing and deployment, ensuring code quality and consistency.\"\n",
    ")\n",
    "\n",
    "# Task 2\n",
    "doc.add_heading('Task 2: Exploratory Data Analysis (EDA)', level=3)\n",
    "doc.add_paragraph(\n",
    "    \"Objective: Gain an understanding of the data, uncover trends, and extract actionable insights.\\n\\n\"\n",
    "    \"Steps:\\n\"\n",
    "    \"1. Descriptive Statistics:\\n\"\n",
    "    \"   - Analyzed headline lengths to understand the distribution of content size.\\n\"\n",
    "    \"   - Identified the most active publishers by counting the number of articles each published.\\n\"\n",
    "    \"   - Examined publication dates to spot trends, including spikes during specific events or on particular days.\\n\"\n",
    "    \"2. Text Analysis (Sentiment Analysis & Topic Modeling):\\n\"\n",
    "    \"   - Performed sentiment analysis on headlines using TextBlob, categorizing them into positive, negative, or neutral sentiments.\\n\"\n",
    "    \"   - Extracted common keywords and phrases using CountVectorizer, which provided insight into frequently discussed topics and key events.\\n\"\n",
    "    \"3. Time Series Analysis:\\n\"\n",
    "    \"   - Analyzed the publication frequency over time, identifying any patterns or spikes that could correspond to significant market events.\\n\"\n",
    "    \"   - Investigated the timing of publications to determine if there were preferred times for releasing news that might influence trading strategies.\\n\"\n",
    "    \"4. Publisher Analysis:\\n\"\n",
    "    \"   - Counted unique publishers and analyzed the type of news reported by the most frequent contributors, which may indicate biases or specific market focuses.\"\n",
    ")\n",
    "\n",
    "# Task 3\n",
    "doc.add_heading('Task 3: Quantitative Analysis Using TA-Lib', level=3)\n",
    "doc.add_paragraph(\n",
    "    \"Objective: Analyze stock data and calculate technical indicators to understand market trends.\\n\\n\"\n",
    "    \"Steps:\\n\"\n",
    "    \"1. Data Preparation:\\n\"\n",
    "    \"   - Loaded stock price data, ensuring it contained essential columns like Open, High, Low, Close, and Volume.\\n\"\n",
    "    \"2. Technical Indicator Calculation:\\n\"\n",
    "    \"   - Calculated key indicators such as Simple Moving Average (SMA), Relative Strength Index (RSI), and Moving Average Convergence Divergence (MACD) using TA-Lib.\\n\"\n",
    "    \"3. Visualization:\\n\"\n",
    "    \"   - Plotted the calculated indicators alongside stock prices to visually inspect their correlation and potential impact on market movements.\"\n",
    ")\n",
    "\n",
    "# Task 4\n",
    "doc.add_heading('Task 4: Correlation Between News Sentiment and Stock Movements', level=3)\n",
    "doc.add_paragraph(\n",
    "    \"Objective: Establish the relationship between news sentiment and stock price movements.\\n\\n\"\n",
    "    \"Steps:\\n\"\n",
    "    \"1. Data Alignment:\\n\"\n",
    "    \"   - Aligned news data with stock price data by normalizing and matching dates, ensuring each news article corresponded to the correct trading day.\\n\"\n",
    "    \"2. Sentiment Analysis:\\n\"\n",
    "    \"   - Used sentiment scores calculated in Task 2 to quantify the emotional tone of the news.\\n\"\n",
    "    \"3. Stock Movement Calculation:\\n\"\n",
    "    \"   - Computed daily stock returns based on closing prices to represent stock movements.\\n\"\n",
    "    \"4. Correlation Analysis:\\n\"\n",
    "    \"   - Calculated the Pearson correlation coefficient between the average daily sentiment scores and the daily stock returns.\\n\"\n",
    "    \"   - Visualized the correlation to assess the strength and direction of the relationship, providing insight into how news sentiment might predict stock movements.\"\n",
    ")\n",
    "\n",
    "# Add a section heading and paragraph\n",
    "doc.add_heading('Results and Insights', level=2)\n",
    "doc.add_paragraph(\n",
    "    \"Headline Lengths: The analysis revealed a wide range of headline lengths, suggesting variability in the depth of content.\\n\\n\"\n",
    "    \"Publisher Activity: Certain publishers were significantly more active, which could indicate their influence on market sentiment.\\n\\n\"\n",
    "    \"Sentiment Trends: The sentiment analysis showed a mix of positive, negative, and neutral sentiments, with specific keywords like 'approval' and 'earnings' frequently appearing in positive contexts.\\n\\n\"\n",
    "    \"Technical Indicators: The SMA, RSI, and MACD provided valuable insights into potential buy/sell signals, which, when aligned with news sentiment, could enhance trading strategies.\\n\\n\"\n",
    "    \"Correlation Analysis: The Pearson correlation coefficient indicated a moderate correlation between news sentiment and stock returns, suggesting that sentiment could be a valuable predictor of market movements.\"\n",
    ")\n",
    "\n",
    "# Add a section heading and paragraph\n",
    "doc.add_heading('Conclusion and Recommendations', level=2)\n",
    "doc.add_paragraph(\n",
    "    \"This project has demonstrated that there is a measurable correlation between financial news sentiment and stock price movements. By integrating sentiment analysis with technical indicators, Nova Financial Solutions can enhance its predictive analytics capabilities. The following recommendations are proposed based on the findings:\\n\\n\"\n",
    "    \"1. Leverage News Sentiment: Incorporate news sentiment analysis into trading algorithms to improve the timing and accuracy of buy/sell decisions.\\n\"\n",
    "    \"2. Focus on Key Publishers: Pay particular attention to news from the most active publishers, as their frequent reports may have a more substantial impact on market sentiment.\\n\"\n",
    "    \"3. Enhance Real-Time Analysis: Implement real-time sentiment analysis tools to react quickly to breaking news, potentially capitalizing on short-term market movements.\"\n",
    ")\n",
    "\n",
    "# Save the document\n",
    "doc.save('Financial_News_Sentiment_Analysis_Report.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
